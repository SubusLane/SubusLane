{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57b621b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded in dataframe\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "#sessions = pd.read_excel(\"C:\\\\Users\\\\subha\\\\Appen\\\\PE Project Report - NWW_V2_1_Wakarusa\\\\9999_Falcon_Project_Wakarusa_MUL_MUL_collection_report.xlsx\",  sheet_name='Sessions')\n",
    "#files = pd.read_excel(\"C:\\\\Users\\\\subha\\\\Appen\\\\PE Project Report - NWW_V2_1_Wakarusa\\\\9999_Falcon_Project_Wakarusa_MUL_MUL_collection_report.xlsx\",  sheet_name='Files')\n",
    "\n",
    "sessions = pd.read_excel(\"C:\\\\Users\\subha\\\\Desktop\\\\Appen\\Wakewords2.1\\\\Data\\\\9999_Falcon_Project_Wakarusa_MUL_MUL_collection_report.xlsx\",  sheet_name='Sessions')\n",
    "files = pd.read_excel(\"C:\\\\Users\\\\subha\\\\Desktop\\\\Appen\\\\Wakewords2.1\\\\Data\\\\9999_Falcon_Project_Wakarusa_MUL_MUL_collection_report.xlsx\",  sheet_name='Files')\n",
    "\n",
    "print(\"data loaded in dataframe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69ec55b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subha\\AppData\\Local\\Temp/ipykernel_9416/1532429656.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  output_data['Hometown'] = output_data['Hometown'].apply(check_type)\n",
      "C:\\Users\\subha\\AppData\\Local\\Temp/ipykernel_9416/1532429656.py:300: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  output_data['Current_hometown'] = output_data['Current_hometown'].apply(check_type)\n",
      "C:\\Users\\subha\\AppData\\Local\\Temp/ipykernel_9416/1532429656.py:302: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  output_data['Hometown'] = output_data['Hometown'].apply(remove_text)\n",
      "C:\\Users\\subha\\AppData\\Local\\Temp/ipykernel_9416/1532429656.py:303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  output_data['Current_hometown'] = output_data['Current_hometown'].apply(remove_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#dropping incomplete\n",
    "#sessions = sessions.loc[sessions['completed'] == '']\n",
    "sessions['completed'] = pd.to_datetime(sessions['completed'], errors='coerce')\n",
    "sessions = sessions[sessions['completed'].notnull()]\n",
    "\n",
    "\n",
    "sessions['input_ethnicity_it'] = \"\"\n",
    "sessions['input_first_language_it'] = \"\" \n",
    "\n",
    "sessions['input_ethnicity_fr'] = \"\"\n",
    "sessions['input_first_language_fr'] = \"\" \n",
    "\n",
    "\n",
    "#separating countries\n",
    "USA_data = sessions.loc[sessions['input_country1'] == 'USA']\n",
    "GBR_data = sessions.loc[sessions['input_country1'] == 'GBR']\n",
    "AUS_data = sessions.loc[sessions['input_country1'] == 'AUS']\n",
    "IT_data = sessions[sessions['input_state_it'].notnull()]\n",
    "FR_data = sessions[sessions['input_state_fr'].notnull()]\n",
    "\n",
    "#aligning corresponding cols to countries\n",
    "USA_data_cols = [\"directory_name\",\"pin\",\"script_name\",\"script_number\",\"total_items\",\"recorded_items\",\"accepted_items\",\"rejected_items\",\"total_duration\",\"date\",\"completed\",\"abandoned\",\"email\",\"input_Current_hometown\",\"input_Mask\",\"input_Socioeconomic_bkgd\",\"input_age\",\"input_age_english\",\"input_ambient\",\"input_city\",\"input_country1\",\"input_date1\",\"input_education\",\"input_english_accent_usa\",\"input_ethnicity_usa\",\"input_first_language_usa\",\"input_gender\",\"input_home_language\",\"input_hometown\",\"input_learned_english\",\"input_other_region_it\",\"input_other_surroundings\",\"input_state_usa\",\"input_surroundings\",\"input_years_in_us\"]\n",
    "GBR_data_cols = [\"directory_name\",\"pin\",\"script_name\",\"script_number\",\"total_items\",\"recorded_items\",\"accepted_items\",\"rejected_items\",\"total_duration\",\"date\",\"completed\",\"abandoned\",\"email\",\"input_Current_hometown\",\"input_Mask\",\"input_Socioeconomic_bkgd\",\"input_age\",\"input_age_english\",\"input_ambient\",\"input_city\",\"input_country1\",\"input_date1\",\"input_education\",\"input_english_accent_gbr\",\"input_ethnicity_gbr\",\"input_first_language_gbr\",\"input_gender\",\"input_home_language\",\"input_hometown\",\"input_learned_english\",\"input_other_region_it\",\"input_other_surroundings\",\"input_state_gbr\",\"input_surroundings\",\"input_years_in_us\"]\n",
    "AUS_data_cols = [\"directory_name\",\"pin\",\"script_name\",\"script_number\",\"total_items\",\"recorded_items\",\"accepted_items\",\"rejected_items\",\"total_duration\",\"date\",\"completed\",\"abandoned\",\"email\",\"input_Current_hometown\",\"input_Mask\",\"input_Socioeconomic_bkgd\",\"input_age\",\"input_age_english\",\"input_ambient\",\"input_city\",\"input_country1\",\"input_date1\",\"input_education\",\"input_english_accent_aus\",\"input_ethnicity_aus\",\"input_first_language_aus\",\"input_gender\",\"input_home_language\",\"input_hometown\",\"input_learned_english\",\"input_other_region_it\",\"input_other_surroundings\",\"input_state_aus\",\"input_surroundings\",\"input_years_in_us\"]\n",
    "IT_data_cols = [\"directory_name\",\"pin\",\"script_name\",\"script_number\",\"total_items\",\"recorded_items\",\"accepted_items\",\"rejected_items\",\"total_duration\",\"date\",\"completed\",\"abandoned\",\"email\",\"input_Current_hometown\",\"input_Mask\",\"input_Socioeconomic_bkgd\",\"input_age\",\"input_age_english\",\"input_ambient\",\"input_city\",\"input_country1\",\"input_date1\",\"input_education\",\"input_english_accent\",\"input_ethnicity_it\",\"input_first_language_it\",\"input_gender\",\"input_home_language\",\"input_hometown\",\"input_learned_italian\",\"input_other_region_it\",\"input_other_surroundings\",\"input_state_it\",\"input_surroundings\",\"input_years_in_us\"]\n",
    "FR_data_cols = [\"directory_name\",\"pin\",\"script_name\",\"script_number\",\"total_items\",\"recorded_items\",\"accepted_items\",\"rejected_items\",\"total_duration\",\"date\",\"completed\",\"abandoned\",\"email\",\"input_Current_hometown\",\"input_Mask\",\"input_Socioeconomic_bkgd\",\"input_age\",\"input_age_english\",\"input_ambient\",\"input_city\",\"input_country1\",\"input_date1\",\"input_education\",\"input_english_accent\",\"input_ethnicity_fr\",\"input_first_language_fr\",\"input_gender\",\"input_home_language\",\"input_hometown\",\"input_learned_french\",\"input_other_region_it\",\"input_other_surroundings\",\"input_state_fr\",\"input_surroundings\",\"input_years_in_us\"]\n",
    "\n",
    "USA_data = USA_data[USA_data_cols]\n",
    "GBR_data = GBR_data[GBR_data_cols]\n",
    "AUS_data = AUS_data[AUS_data_cols]\n",
    "IT_data = IT_data[IT_data_cols]\n",
    "FR_data = FR_data[FR_data_cols]\n",
    "\n",
    "#Columned renamed for all to make it common\n",
    "common_cols = [\"directory_name\",\"pin\",\"script_name\",\"script_number\",\"total_items\",\"recorded_items\",\"accepted_items\",\"rejected_items\",\"total_duration\",\"date\",\"completed\",\"abandoned\",\"email\",\"input_Current_hometown\",\"input_Mask\",\"input_Socioeconomic_bkgd\",\"input_age\",\"input_age_english\",\"input_ambient\",\"input_city\",\"input_country1\",\"input_date1\",\"input_education\",\"input_english_accent\",\"input_ethnicity\",\"input_first_language\",\"input_gender\",\"input_home_language\",\"input_hometown\",\"input_learned\",\"input_other_region\",\"input_other_surroundings\",\"input_state\",\"input_surroundings\",\"input_years_in\"]\n",
    "\n",
    "countries_name = [USA_data,GBR_data,AUS_data,IT_data,FR_data]\n",
    "for cntry in countries_name:\n",
    "    cntry.columns = common_cols\n",
    "stacked_data = pd.concat(countries_name, ignore_index=True)\n",
    "\n",
    "\n",
    "#FR and IT country data filling\n",
    "stacked_data.loc[stacked_data['script_name'].str.contains('it', case=False), 'input_country1'] = 'ITA'\n",
    "stacked_data.loc[stacked_data['script_name'].str.contains('fr', case=False), 'input_country1'] = 'FRA'\n",
    "stacked_data['member_id'] = stacked_data['pin']\n",
    "#merging files data with session data\n",
    "stacked_data = pd.merge(files,stacked_data, how='left', on = 'directory_name')\n",
    "#dropping blank rows\n",
    "stacked_data = stacked_data.loc[stacked_data['member_id'].notnull()]\n",
    "#sorting\n",
    "stacked_data=stacked_data.sort_values(['directory_name', 'promptnum'], ascending=[True, True])\n",
    "#creaing required cols\n",
    "stacked_data[\"prompt_text\"] = stacked_data[\"Identifier\"]+\", \"+ stacked_data[\"Utts\"]\n",
    "stacked_data['style'] = \"Scripted\"\n",
    "stacked_data['scope'] = \"in domain\"\n",
    "stacked_data[\"project\"] = \"\"\n",
    "stacked_data[\"locale\"] = \"\"\n",
    "stacked_data.loc[stacked_data['input_country1'].str.contains('USA', case=False), 'locale'] = 'en_US'\n",
    "stacked_data.loc[stacked_data['input_country1'].str.contains('GBR', case=False), 'locale'] = 'en_GB'\n",
    "stacked_data.loc[stacked_data['input_country1'].str.contains('AUS', case=False), 'locale'] = 'en_AU'\n",
    "stacked_data.loc[stacked_data['input_country1'].str.contains('IT', case=False), 'locale'] = 'it_IT'\n",
    "stacked_data.loc[stacked_data['input_country1'].str.contains('FR', case=False), 'locale'] = 'fr_FR'\n",
    "\n",
    "stacked_data.loc[stacked_data['input_country1'].str.contains('USA', case=False), 'project'] = 'T154939089_New_WakeWords_2.1_EN_US'\n",
    "stacked_data.loc[stacked_data['input_country1'].str.contains('GBR', case=False), 'project'] = 'T154939089_New_WakeWords_2.1_EN_GB'\n",
    "stacked_data.loc[stacked_data['input_country1'].str.contains('AUS', case=False), 'project'] = 'T154939089_New_WakeWords_2.1_EN_AU'\n",
    "stacked_data.loc[stacked_data['input_country1'].str.contains('IT', case=False), 'project'] = 'T154939089_New_WakeWords_2.1_IT_IT'\n",
    "stacked_data.loc[stacked_data['input_country1'].str.contains('FR', case=False), 'project'] = 'T154939089_New_WakeWords_2.1_FR_FR'\n",
    "\n",
    "stacked_data[['ambi1','ambi2', 'ambi3', 'ambi4']] = stacked_data['input_ambient'].str.split('_', expand=True)\n",
    "stacked_data[\"environment\"] = stacked_data['ambi1']+\"_\"+stacked_data['ambi2']+\"_\"+stacked_data['ambi3']\n",
    "stacked_data[\"noise_type\"] = stacked_data['ambi4']\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y%m%d\")\n",
    "stacked_data[\"vendor_ds\"] = dt_string #Current date \n",
    "stacked_data[\"bluetooth\"] = \"\"\n",
    "stacked_data[\"transcription\"] = \"\"\n",
    "stacked_data[\"english_accent_locale\"] = \"\"\n",
    "stacked_data[\"conversation_id\"] = \"\" #stacked_data['member_id']+\"_\"+stacked_data['promptnum'].astype(str)\n",
    "stacked_data[\"biometric_consent\"] = \"No\"\n",
    "stacked_data['SNRdB'] = \"\"\n",
    "stacked_data['BkgRmsdB'] = \"\"\n",
    "stacked_data['SigRMSdB'] = \"\"\n",
    "stacked_data['SigthreshdB'] = \"\"\n",
    "stacked_data['child_language'] = \"n/a\"\n",
    "stacked_data['Topic'] = stacked_data['Identifier']\n",
    "\n",
    "#renaming cols\n",
    "col_map={'Subtitle' : 'subtitle',\n",
    "'Topic' : 'topic',\n",
    "'member_id' : 'member_id',\n",
    "'prompt_text' : 'prompt_text',\n",
    "'file' : 'audio_filename',\n",
    "'input_gender' : 'gender',\n",
    "'input_age' : 'age',\n",
    "'input_city' : 'city',\n",
    "'input_state' : 'state',\n",
    "'input_age_english' : 'age_english',\n",
    "'input_first_language' : 'first_language',\n",
    "'input_home_language' : 'home_language',\n",
    "'input_years_in' : 'years_in_us',\n",
    "'style' : 'style',\n",
    "'environment' : 'environment',\n",
    "'vendor_ds' : 'vendor_ds',\n",
    "'scope' : 'scope',\n",
    "'project' : 'project',\n",
    "'locale' : 'locale',\n",
    "'input_education' : 'education',\n",
    "'bluetooth' : 'bluetooth',\n",
    "'noise_type' : 'noise_type',\n",
    "'transcription' : 'transcription',\n",
    "'input_country1' : 'country',\n",
    "'input_surroundings' : 'environment_description',\n",
    "'input_other_surroundings' : 'environment_description_other',\n",
    "'input_Mask' : 'face_mask',\n",
    "'SNRdB' : 'SNRdB',\n",
    "'BkgRmsdB' : 'BkgRmsdB',\n",
    "'SigRMSdB' : 'SigRMSdB',\n",
    "'SigthreshdB' : 'SigthreshdB',\n",
    "'input_Socioeconomic_bkgd' : 'Socioeconomic_bkgd',\n",
    "'input_hometown' : 'Hometown',\n",
    "'input_ethnicity' : 'Ethnicity',\n",
    "'input_Current_hometown' : 'Current_hometown',\n",
    "'child_language': 'child_language',\n",
    "'input_english_accent' : 'english_accent',\n",
    "'english_accent_locale' : 'english_accent_locale',\n",
    "'conversation_id' : 'conversation_id',\n",
    "'biometric_consent' : 'biometric_consent'\n",
    "}\n",
    "stacked_data = stacked_data.rename(columns=col_map)\n",
    "\n",
    "#cleaning cols\n",
    "gender_val = {\n",
    "\"Uomo\":\"Male\",\n",
    "\"Homme\":\"Male\",\n",
    "\"Donna\":\"Female\",\n",
    "\"Femme\":\"Female\",\n",
    "\"Non Binario\":\"Non-Binary\",\n",
    "\"Non-binaire\":\"Non-Binary\",\n",
    "}\n",
    "stacked_data['gender'] = stacked_data['gender'].replace(gender_val)\n",
    "city_val = {\n",
    "\"rurale\":\"Rural\",\n",
    "\"urbano\":\"Urban\",\n",
    "\"suburbano\":\"Suburban\",\n",
    "\"Campagne\":\"Rural\",\n",
    "\"Ville de banlieue\":\"Suburban\",\n",
    "\"Aire urbaine\":\"Urban\"\n",
    "}\n",
    "stacked_data['city'] = stacked_data['city'].replace(city_val)\n",
    "\n",
    "stacked_data.loc[stacked_data['script_name'].str.contains('it', case=False), 'first_language'] = 'Italian'\n",
    "stacked_data.loc[stacked_data['script_name'].str.contains('fr', case=False), 'first_language'] = 'French'\n",
    "\n",
    "mask_val = {\n",
    "    \"Non\":\"No\",\n",
    "    \"Oui\":\"Yes\",\n",
    "    \"Si\":\"Yes\"\n",
    "}\n",
    "stacked_data['face_mask'] = stacked_data['face_mask'].replace(mask_val)\n",
    "\n",
    "envsur_val = {\n",
    "\"I: A casa con la TV / elettrodomestico accesi\":\"I: Home with TV/noisy appliance on\",\n",
    "\"I: A casa con persone che parlano/bambini\":\"I: Home with people talking/kids\",\n",
    "\"I: All'Al chiuso di luoghi pubblici\":\"I: Inside noisy public buildings/places\",\n",
    "\"I: A casa senza molto rumore\":\"I: Home with not much noise\",\n",
    "\"I: Altro\":\"I: Other\",\n",
    "\"I: A la maison avec une TV ou des appareils électroménagers allumés\":\"I: Home with TV/noisy appliance on\",\n",
    "\"I: A la maison avec des gens qui parlent/des enfants\":\"I: Home with people talking/kids\",\n",
    "\"I: Dans un lieu public en intérieur\":\"I: Inside noisy public buildings/places\",\n",
    "\"I: A la maison sans trop de bruit\":\"I: Home with not much noise\",\n",
    "\"I: Autre\":\"I: Other\"\n",
    "}\n",
    "stacked_data['environment_description'] = stacked_data['environment_description'].str.strip()\n",
    "stacked_data['environment_description'] = stacked_data['environment_description'].replace(envsur_val)\n",
    "\n",
    "env_val = {\n",
    "\"Al chiuso_rumoroso_alto\":\"indoor_noisy_loud\",\n",
    "\"Al chiuso_rumoroso_normale\":\"indoor_noisy_normal\",\n",
    "\"Al chiuso_rumoroso_basso\":\"indoor_noisy_lowvolume\",\n",
    "\"Al chiuso_tranquillo_alto\":\"indoor_quiet_loud\",\n",
    "\"Al chiuso_tranquillo_normale\":\"indoor_quiet_normal\",\n",
    "\"Al chiuso_tranquillo_basso\":\"indoor_quiet_lowvolume\",\n",
    "    \n",
    "\"interieur_bruyant_fort\":\"indoor_noisy_loud\",\n",
    "\"interieur_bruyant_volumenormal\":\"indoor_noisy_normal\",\n",
    "\"interieur_bruyant_volumefaible\":\"indoor_noisy_lowvolume\",\n",
    "\"interieur_calme_volumefort\":\"indoor_quiet_loud\",\n",
    "\"interieur_calme_volumenormal\":\"indoor_quiet_normal\",\n",
    "\"interieur_calme_volumefaible\":\"indoor_quiet_lowvolume\",\n",
    "    \n",
    "\"interieur_bruyant_volumefort\":\"indoor_noisy_loud\",    \n",
    "}\n",
    "stacked_data['environment'] =stacked_data['environment'].str.strip()\n",
    "stacked_data['environment'] = stacked_data['environment'].replace(env_val)\n",
    "\n",
    "noise_val = {\n",
    "\"umano\":\"Human Speech\",\n",
    "\"ambientale\":\"Ambient Speech\",\n",
    "\"non parlato\":\"Non-Speech\",\n",
    "\"voix humaine\":\"Human Speech\",\n",
    "\"voixbruitdefond\":\"Ambient Speech\",\n",
    "\"aucunevoixhumaine\":\"Non-Speech\",\n",
    "\n",
    "\"voixhumaine\":\"Human Speech\", \n",
    "\"ambient speech\":\"Ambient Speech\",\n",
    "\"human speech\":\"Human Speech\", \n",
    "\"non-speech\":\"Non-Speech\",    \n",
    "}\n",
    "stacked_data['noise_type'] =stacked_data['noise_type'].str.strip()\n",
    "stacked_data['noise_type'] = stacked_data['noise_type'].replace(noise_val)\n",
    "\n",
    "sco_val = {\n",
    "            \"< 22 000 euros\":\"Low\",\n",
    "            \"22 000 a 50 000 euros\":\"Medium\",\n",
    "            \"50 000 euros et +\":\"Affluent\",\n",
    "            \"< 21k €\":\"Low\",\n",
    "            \"21k € - 48k €\":\"Medium\",\n",
    "            \"> 48k+ €\":\"Affluent\"    \n",
    "}\n",
    "stacked_data['Socioeconomic_bkgd'] = stacked_data['Socioeconomic_bkgd'].replace(sco_val)\n",
    "\n",
    "edu_val={\n",
    "#ITA\n",
    "\"Dottorato\":\"Doctorate\",\n",
    "\"Laurea magistrale\":\"Masters Degree\",\n",
    "\"Master\":\"Masters Degree\",\n",
    "\"Laruea triennale\":\"Bachelor Degree\",\n",
    "\"Studi universitari in corso\":\"Some College\",\n",
    "\"Diploma scuola superiore\":\"High School\",\n",
    "\"Diploma scuola media\":\"Middle School\",\n",
    "\"Diploma scuola elementare\":\"Elementary School\",\n",
    "\"Altro\":\"Other\",\n",
    "#FRA    \n",
    "\"DUT/BTS/BAC+2\":\"Associates Degree\",\n",
    "\"Licence/BAC+3\":\"Bachelors Degree\",\n",
    "\"En etudes superieures actuellement\":\"Some College\",\n",
    "\"Doctorat\":\"Doctorate\",\n",
    "\"Ecole primaire\":\"Elementary School\",\n",
    "\"Lycee\":\"High School\",\n",
    "\"Master/BAC+5\":\"Masters Degree\",\n",
    "\"College/Brevet\":\"Some College\",\n",
    "\"Ai eu des cours a l'universite sans terminer\":\"Some College\",\n",
    "\"Autre\":\"Other\",\n",
    "    #eng\n",
    "\"Doctorate\":\"Doctorate\",\n",
    "\"Masters_degree\":\"Masters Degree\",\n",
    "\"Bachelor_degree\": \"Bachelors Degree\",\n",
    "\"Associate_degree\": \"Associates Degree\" ,\n",
    "\"Some_college\":\"Some College\",\n",
    "\"High_school\":\"High School\",\n",
    "\"Middle_school\":\"Middle School\",\n",
    "\"Elementary_school\": \"Elementary School\"\n",
    "}\n",
    "stacked_data['education'] = stacked_data['education'].replace(edu_val)\n",
    "\n",
    "\n",
    "acc_val ={\n",
    "    \n",
    "\"Alsace, Aquitaine, Auvergne, Brittany, Burgundy, Centre-Val de Loire, Champagne- Ardenne, Franche-Comté, Île-de-France,\":\"Alsace, Aquitaine, Auvergne, Brittany, Burgundy, Centre-Val de Loire, Champagne- Ardenne, Franche-Comté, Île-de-France, Languedoc-Roussillon, Limousin, Lorraine, Lower Normandy, Midi-Pyrénées, Nord-Pas-de-Calais, Pays de la Loire, Picardy, Poitou-Charentes, Provence-Alpes-Côte d'Azur, Rhône-Alpes, Upper Normandy\",\n",
    "\"Languedoc-Roussillon, Limousin, Lorraine, Lower Normandy, Midi-Pyrénées, Nord-Pas-de-Calais, Pays de la Loire, Picardy, Poitou-Charentes, Provence-Alpes-Côte d'Azur, Rhône-Alpes, Upper Normandy \":\"Alsace, Aquitaine, Auvergne, Brittany, Burgundy, Centre-Val de Loire, Champagne- Ardenne, Franche-Comté, Île-de-France, Languedoc-Roussillon, Limousin, Lorraine, Lower Normandy, Midi-Pyrénées, Nord-Pas-de-Calais, Pays de la Loire, Picardy, Poitou-Charentes, Provence-Alpes-Côte d'Azur, Rhône-Alpes, Upper Normandy\",\n",
    "\"Languedoc-Roussillon, Limousin, Lorraine, Lower Normandy, Midi-Pyrénées, Nord-Pas-de-Calais, Pays de la Loire, Picardy, Poitou-Charentes, Provence-Alpes-Côte d\":\"Alsace, Aquitaine, Auvergne, Brittany, Burgundy, Centre-Val de Loire, Champagne- Ardenne, Franche-Comté, Île-de-France, Languedoc-Roussillon, Limousin, Lorraine, Lower Normandy, Midi-Pyrénées, Nord-Pas-de-Calais, Pays de la Loire, Picardy, Poitou-Charentes, Provence-Alpes-Côte d'Azur, Rhône-Alpes, Upper Normandy\",\n",
    "\n",
    "\"Canadian French (Quebecois, Acadian, Franco-Ontarian)\":\"Canadian French (Quebecois, Acadian, Franco-Ontarian)\",  \n",
    "\"Dialects from former French colonies in Africa (DR of Congo, Ivory Coast, Senegal, Morocco, Algeria, Mali, Guinea, Niger, Nigeria, Chad, Madagascar) \":\"Dialects from former French colonies in Africa (DR of Congo, Ivory Coast, Senegal, Morocco, Algeria, Mali, Guinea, Niger, Nigeria, Chad, Madagascar)\", \n",
    "\"Autres (Haiti, United States (Cajun), Laos, Cambodia, Vietnam, Lebanon) \":\"Other (Haiti, United States (Cajun), Laos, Cambodia, Vietnam, Lebanon)\" \n",
    "}\n",
    "stacked_data['english_accent'] = stacked_data['english_accent'].replace(acc_val)\n",
    "\n",
    "#Excluding already delivered data\n",
    "delivered_data = pd.read_excel(\"C:\\\\Users\\\\subha\\\\Appen\\\\Falcon Speech Collection 2023 - NWW 2.1\\\\tracker\\\\Sources\\\\delivery_report.xlsx\")\n",
    "# Find the intersection of the two dataframes\n",
    "intersection = stacked_data[stacked_data['directory_name'].isin(delivered_data['directory_name'])]\n",
    "stacked_data = stacked_data.drop(intersection.index)\n",
    "\n",
    "#final cols selected\n",
    "col_final = [\"subtitle\",\"topic\",\"member_id\",\"prompt_text\",\"audio_filename\",\"gender\",\"age\",\"city\",\"state\",\n",
    "             \"age_english\",\"first_language\",\"home_language\",\"years_in_us\",\"style\",\"environment\",\"vendor_ds\",\n",
    "             \"scope\",\"project\",\"locale\",\"education\",\"bluetooth\",\"noise_type\",\"transcription\",\"country\",\n",
    "             \"environment_description\",\"environment_description_other\",\"face_mask\",\"SNRdB\",\"BkgRmsdB\",\n",
    "             \"SigRMSdB\",\"SigthreshdB\",\"Socioeconomic_bkgd\",\"Hometown\",\"Ethnicity\",\"Current_hometown\",\"child_language\",\n",
    "             \"english_accent\",\"english_accent_locale\",\"conversation_id\",\"biometric_consent\"]\n",
    "output_data = stacked_data[col_final]\n",
    "\n",
    "# Remove text after , / . (\n",
    "def remove_text(text):\n",
    "    for char in [',', '/', '.', '(']:\n",
    "        text = text.split(char)[0]\n",
    "    return text\n",
    "\n",
    "# Check the type of each value in the column1 column\n",
    "def check_type(text):\n",
    "    if type(text) == float:\n",
    "        return str(text)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "output_data['Hometown'] = output_data['Hometown'].apply(check_type)\n",
    "output_data['Current_hometown'] = output_data['Current_hometown'].apply(check_type)\n",
    "\n",
    "output_data['Hometown'] = output_data['Hometown'].apply(remove_text)\n",
    "output_data['Current_hometown'] = output_data['Current_hometown'].apply(remove_text)\n",
    "\n",
    "stacked_data.to_excel(\"C:\\\\Users\\\\subha\\\\Desktop\\\\Appen\\\\Wakewords2.1\\\\Data\\\\staked_output.xlsx\", index=False)\n",
    "output_data.to_excel(\"C:\\\\Users\\\\subha\\\\Desktop\\\\Appen\\\\Wakewords2.1\\\\Data\\\\output_data.xlsx\", index=False)\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9e3f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "100b5638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2812edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sessions = pd.read_excel(\"C:\\\\Users\\\\subha\\\\Appen\\\\Falcon Speech Collection 2023 - NWW 2.1\\\\package\\\\20230721\\\\output_data_20230721.xlsx\",  sheet_name='Sheet1')\n",
    "\n",
    "USA_data = sessions.loc[sessions['country'] == 'USA']\n",
    "GBR_data = sessions.loc[sessions['country'] == 'GBR']\n",
    "AUS_data = sessions.loc[sessions['country'] == 'AUS']\n",
    "IT_data = sessions[sessions['country'] == 'ITA']\n",
    "FR_data = sessions[sessions['country'] == 'FRA']\n",
    "\n",
    "countries_name = [USA_data,GBR_data,AUS_data,IT_data,FR_data]\n",
    "nameC=[\"EN_US\",\"EN_GB\",\"EN_AU\",\"IT_IT\",\"FR_FR\"]\n",
    "date=\"20230721\"\n",
    "for x,y in zip(countries_name,nameC):\n",
    "    x.to_excel(\"C:\\\\Users\\\\subha\\\\Appen\\\\Falcon Speech Collection 2023 - NWW 2.1\\\\package\\\\{}\\\\Appen_VoiceDataCollectionServices_{}_New_WakeWords_2_1_{}.xlsx\".format(date,date,y), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6ca266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
